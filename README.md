# ğŸ§  Adaptive LoRA Fine-Tuned MCQ Generator

![Python](https://img.shields.io/badge/Python-3.10-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-orange)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![PEFT](https://img.shields.io/badge/PEFT-LoRA-green)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-red)
![Status](https://img.shields.io/badge/Status-Production--Ready-brightgreen)

---

## ğŸ“¸ Application Demo

![App Demo](assets/app_demo.png)

---

## ğŸš€ Project Overview

This project implements a **LoRA fine-tuned Large Language Model pipeline** for automatic Multiple Choice Question (MCQ) generation.

It compares:

- Base model performance
- LoRA fine-tuned model performance
- Inference speed
- Automatic NLP evaluation metrics

The system demonstrates practical LLM optimization using parameter-efficient fine-tuning.

---

## ğŸ§  Base Model

- **Model:** google/flan-t5-base
- Framework: Hugging Face Transformers
- Fine-Tuning: LoRA (Low-Rank Adaptation) using PEFT

---

## âš™ï¸ System Architecture

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   User Input Text  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   FLAN-T5 Tokenizer  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Base FLAN-T5    â”‚           â”‚  LoRA Fine-Tuned  â”‚
â”‚     Model         â”‚           â”‚       Model       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                 â”‚
          â–¼                                 â–¼
   Generated MCQ                     Generated MCQ
          â”‚                                 â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Evaluation Module  â”‚
               â”‚ BLEU / ROUGE /     â”‚
               â”‚ BERTScore          â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Evaluation Metrics

The system automatically evaluates generated MCQs using:

- BLEU
- ROUGE-L
- BERTScore (semantic similarity)

This provides both lexical and semantic quality comparison.

---

## ğŸ”¬ Technical Stack

- Python 3.10
- PyTorch
- Transformers (Hugging Face)
- PEFT (LoRA)
- Sentence-Transformers
- FAISS (vector similarity support)
- Streamlit (frontend UI)

---

## ğŸ“ Project Structure

```
mcq-rag-app/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ mcq_lora_model/
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â””â”€â”€ adapter_model.safetensors
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ app_demo.png
â””â”€â”€ README.md
```

---

## ğŸ–¥ï¸ Run Locally

```bash
git clone https://github.com/swati-mishra07/mcq-rag-app.git
cd mcq-rag-app

python -m venv venv
venv\Scripts\activate

pip install -r requirements.txt
streamlit run app.py
```

---

## ğŸ’¡ Key ML Concepts Demonstrated

- Parameter Efficient Fine-Tuning (LoRA)
- Transformer-based Sequence-to-Sequence models
- Model comparison benchmarking
- Inference latency measurement
- NLP automatic evaluation metrics
- Modular ML application design

---

## ğŸ“ˆ Real-World Applications

- AI-based education systems
- Automated assessment generation
- EdTech platforms
- Curriculum design automation
- Smart content generation tools

---

## ğŸ§ª Future Improvements

- Full Retrieval-Augmented Generation (RAG) pipeline
- Batch dataset benchmarking
- REST API deployment
- Model quantization for faster inference
- Production-grade Docker containerization

---

## ğŸ‘©â€ğŸ’» Author

Swati Mishra  
Computer Science (IT) Undergraduate  
Machine Learning & AI Enthusiast  

GitHub: https://github.com/swati-mishra07